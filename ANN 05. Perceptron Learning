'''
# 1. Downgrade NumPy to a compatible version
pip install numpy==1.24.4

# 2. Install matplotlib for plotting
pip install matplotlib

# 3. Install scikit-learn for machine learning models
pip install scikit-learn

'''

''' ADD IRIS DATASET '''
# Import necessary libraries
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.linear_model import Perceptron
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Load the iris dataset
iris = load_iris()
X = iris.data[:100, [0, 2]]  # Select features: sepal length (0), petal length (2)
y = iris.target[:100]        # Select two classes: Setosa(0) and Versicolor(1)

# Split the dataset into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)

# Feature scaling (important for perceptron convergence)
scaler = StandardScaler()
X_train_std = scaler.fit_transform(X_train)
X_test_std = scaler.transform(X_test)

# Create and train the Perceptron model
ppn = Perceptron(max_iter=40, eta0=0.1, random_state=1)
ppn.fit(X_train_std, y_train)

# Evaluate the model
print(f'Misclassified samples: {(y_test != ppn.predict(X_test_std)).sum()}')
print(f'Accuracy: {ppn.score(X_test_std, y_test) * 100:.2f}%')

# Function to plot decision boundary
def plot_decision_regions(X, y, classifier, title):
    from matplotlib.colors import ListedColormap

    # Create a meshgrid for plotting decision boundaries
    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx1, xx2 = np.meshgrid(
        np.arange(x1_min, x1_max, 0.02),
        np.arange(x2_min, x2_max, 0.02)
    )
    
    # Predict for each point in the meshgrid
    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)
    Z = Z.reshape(xx1.shape)

    # Plot contour and data points
    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=ListedColormap(('red', 'blue')))
    plt.xlim(xx1.min(), xx1.max())
    plt.ylim(xx2.min(), xx2.max())

    # Plot class samples
    for idx, cl in enumerate(np.unique(y)):
        plt.scatter(x=X[y == cl, 0], 
                    y=X[y == cl, 1],
                    alpha=0.8, 
                    c=('red', 'blue')[idx],
                    marker='o', 
                    label=iris.target_names[cl])

    plt.xlabel('Sepal length (standardized)')
    plt.ylabel('Petal length (standardized)')
    plt.title(title)
    plt.legend(loc='upper left')
    plt.grid(True)
    plt.show()

# Plot the decision region for training data
plot_decision_regions(X_train_std, y_train, classifier=ppn, title="Perceptron Decision Region (Training Set)")
